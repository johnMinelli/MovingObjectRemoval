{
  "cells":[
    {
      "cell_type":"code",
      "source":[
        "from termcolor import colored\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy import ndimage, misc\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage import filters\n",
        "import time\n",
        "import progressbar\n",
        "from pathlib import Path\n",
        "\n",
        "files = [str(a) for a in Path(\"targetdir\").glob('**\/*.mp4')]"
      ],
      "execution_count":1,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "**Recalculate foundamental matrix from eight-point method using only background feature points**\n",
        "this process can be reapplied iterativly until the foundamental matrix converge on a reliable result and moreover can be applied a RANSAC algorithm to clean from outliers"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "**Get epipolar lines from the two frame (feature points by SIFT)** "
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def l1_distance(img1, img2):\n",
        "    diff = np.abs(img1-img2)\n",
        "    if img1.shape[-1] ==  3 and len(img1.shape)==3:\n",
        "        diff = np.sum(diff, axis=-1)\n",
        "    return diff\n",
        "\n",
        "def l2_distance(img1, img2):\n",
        "    sq_dist = (img1-img2)**2\n",
        "    if img1.shape[-1] ==  3 and len(img1.shape)==3:\n",
        "        sq_dist = np.sum(sq_dist,axis=-1)\n",
        "    diff = np.sqrt(sq_dist)\n",
        "    return diff\n",
        "\n",
        "def max_distance(img1, img2):\n",
        "    diff = np.abs(img1-img2)\n",
        "    if img1.shape[-1] ==  3 and len(img1.shape)==3:\n",
        "        diff = np.max(diff, axis=-1)\n",
        "    return diff"
      ],
      "execution_count":3,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def drawlines(img1,img2,lines,pts1,pts2):\n",
        "    ''' img1 - image on which we draw the epilines for the points in img2\n",
        "        lines - corresponding epilines '''\n",
        "    r,c = img1.shape\n",
        "    img1 = cv2.cvtColor(img1,cv2.COLOR_GRAY2BGR)\n",
        "    img2 = cv2.cvtColor(img2,cv2.COLOR_GRAY2BGR)\n",
        "    for r,pt1,pt2 in zip(lines,pts1,pts2):\n",
        "        color = tuple(np.random.randint(0,255,3).tolist())\n",
        "        x0,y0 = map(int, [0, -r[2]\/r[1] ])\n",
        "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)\/r[1] ])\n",
        "        # img1 = cv2.line(img1, (x0,y0), (x1,y1), color,1)\n",
        "        img1 = cv2.circle(img1,tuple(pt1),5,color,-1)\n",
        "        img2 = cv2.circle(img2,tuple(pt2),5,color,-1)\n",
        "    return img1,img2"
      ],
      "execution_count":4,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "\n",
        "#  https:\/\/www.pyimagesearch.com\/2015\/04\/06\/zero-parameter-automatic-canny-edge-detection-with-python-and-opencv\/\n",
        "# \n",
        "\n",
        "def auto_canny(image, sigma=0.33):\n",
        "\t''' lower value of sigma indicates a tighter threshold, whereas a larger value of sigma gives a wider threshold '''\n",
        "\n",
        "\t# compute the median of the single channel pixel intensities\n",
        "\tv = np.median(image)\n",
        "\t# apply automatic Canny edge detection using the computed median\n",
        "\tlower = int(max(0, (1.0 - sigma) * v))\n",
        "\tupper = int(min(255, (1.0 + sigma) * v))\n",
        "\tedged = cv2.Canny(image, lower, upper)\n",
        "\t# return the edged image\n",
        "\treturn edged"
      ],
      "execution_count":5,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "#  https:\/\/docs.opencv.org\/4.5.1\/d5\/d0f\/tutorial_py_gradients.html\n",
        "\n",
        "def count_oriented(img, show=False):\n",
        "  ''' count the points in a binary image taking in consideration the orientation '''\n",
        "\n",
        "    # sobel derivatives\n",
        "  derivX = cv2.Sobel(img, cv2.CV_32F, 1, 0)\n",
        "  derivY = cv2.Sobel(img, cv2.CV_32F, 0, 1)\n",
        "\n",
        "  mag = cv2.magnitude(np.absolute(derivX), np.absolute(derivY))\n",
        "  \n",
        "    # thresholding of the magnitude values\n",
        "  thresh = 1000\n",
        "  _, mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)\n",
        "  mask = np.uint8(mask>0)\n",
        "  \n",
        "  if show:\n",
        "    plt.figure(figsize=(15,10)); plt.title(\"Mask magnitude min: {} max: {}\".format(np.int(np.min(mag[mag>0])), np.int(np.max(mag))))\n",
        "    plt.imshow(cv2.cvtColor(mask*255, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "  \n",
        "  return np.sum(mask)"
      ],
      "execution_count":6,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def expand_borders(m): return cv2.dilate(m, None, iterations=5)\n",
        "def enhance_borders(im, k=np.array([[-1,-1,-1], [-1, 9,-1], [-1,-1,-1]])): return cv2.GaussianBlur(im, (3, 3), 0) # cv2.filter2D(im, -1, k) #"
      ],
      "execution_count":7,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# This functions is used to determine if the bound (the next_bound) around the moving object is done correctly evaluating\n",
        "# the difference between the two images in the ipotetical static zone:\n",
        "\n",
        "index = 0\n",
        "\n",
        "def spot_the_diff(image1_gray, image2_gray, log=False, show_work=True, debug_init=True):\n",
        "    ''' Given two images return the one with the object  \n",
        "          image1_gray: [prev_bound - next_bound] * prev_show\n",
        "          image2_gray: [prev_bound - next_bound] * next_frame\n",
        "    ret=> if bound was correct the diff function will find dirt in image1 (=>1) or image1 and image2 are equals (=>0)\n",
        "          if bound was incorrect the diff function will contain some moving parts of image2 (=>2)\n",
        "             (can happen that also identifies small part like light changes of image1 but returns 2) ''' \n",
        "\n",
        "    if debug_init:\n",
        "        global index\n",
        "        plt.figure(figsize=(15,15))\n",
        "        plt.subplot(121); plt.title(\"PREV {}\".format(index))\n",
        "        plt.imshow(cv2.cvtColor(image1_gray, cv2.COLOR_BGR2RGB))\n",
        "        plt.subplot(122); plt.title(\"NEXT\")\n",
        "        plt.imshow(cv2.cvtColor(image2_gray, cv2.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "        plt.imsave(\"spot_debug\/prev_{}.jpg\".format(index),cv2.cvtColor(image1_gray, cv2.COLOR_BGR2RGB))\n",
        "        plt.imsave(\"spot_debug\/next_{}.jpg\".format(index),cv2.cvtColor(image2_gray, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    (score, sim) = ssim(image1_gray, image2_gray, full=True)\n",
        "    sim = np.uint8(sim*255)\n",
        "    thresh_sim =  np.uint8(np.logical_not(cv2.threshold(sim, 205, 255, cv2.THRESH_BINARY)[1])*255)\n",
        "    thresh_sim = cv2.medianBlur(thresh_sim, 7)\n",
        "    sum_sim = np.sum(thresh_sim>0)\n",
        "\n",
        "      # lower bound (low thresh, high detection)\n",
        "    if sum_sim<100:\n",
        "        print(colored(\"Equality_l\", 'blue'))\n",
        "        return 0\n",
        "\n",
        "    dif = cv2.absdiff(image1_gray, image2_gray)\n",
        "    thresh_dif = cv2.medianBlur(dif, 5)\n",
        "\n",
        "      # higher bound (high thresh, low detection)\n",
        "    if not np.any(thresh_dif>50):\n",
        "        print(colored(\"Equality_h\", 'blue'))\n",
        "        return 0\n",
        "\n",
        "    if show_work:\n",
        "        plt.figure(figsize=(20,20))\n",
        "        plt.subplot(131); plt.title(\"ssim\")\n",
        "        plt.imshow(cv2.cvtColor(np.uint8(thresh_sim), cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    adaptive=0\n",
        "    detected = 110\n",
        "    a=None\n",
        "    while(detected>80 if detected<100 else detected>105):\n",
        "        a = np.uint8(thresh_dif>adaptive)*255\n",
        "        detected = ((np.sum(a>0)\/sum_sim)*100).round(3)\n",
        "        if log: print(\"Not {}%\"-format(detected.round(2)))\n",
        "        adaptive+=10\n",
        "\n",
        "    mask = cv2.morphologyEx(a,cv2.MORPH_CLOSE, np.ones((12,12),np.uint8))\n",
        "    mask = cv2.medianBlur(mask,3)\n",
        "    gradient = cv2.morphologyEx(mask, cv2.MORPH_GRADIENT, np.ones((6,6),np.uint8))\n",
        "\n",
        "    if show_work:\n",
        "        plt.subplot(132); plt.title(\"Mask closed [{}]\".format(adaptive-10))\n",
        "        plt.imshow(cv2.cvtColor(np.uint8(mask), cv2.COLOR_BGR2RGB))\n",
        "        plt.subplot(133); plt.title(\"Mask gradient [{}%]\".format(detected.round(1)))\n",
        "        plt.imshow(cv2.cvtColor(np.uint8(gradient), cv2.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "\n",
        "      # canny in the border of the movement areas\n",
        "    blurred1 = enhance_borders(image1_gray*(gradient>0))\n",
        "    blurred2 = enhance_borders(image2_gray*(gradient>0))\n",
        "\n",
        "    edges1 = auto_canny(blurred1)\n",
        "    edges2 = auto_canny(blurred2)\n",
        "\n",
        "      # count of canny oriented pixels in the border of the movement areas \n",
        "    i1=count_oriented(edges1)\n",
        "    i2=count_oriented(edges2)\n",
        "    if log: print(i1)\n",
        "    if log: print(i2)\n",
        "\n",
        "    if show_work:\n",
        "        plt.figure(figsize=(20,20))\n",
        "        plt.subplot(121)\n",
        "        plt.title(\"Canny 1 [{}]\".format(i1))\n",
        "        plt.imshow(cv2.cvtColor(edges1, cv2.COLOR_BGR2RGB))\n",
        "        plt.subplot(122)\n",
        "        plt.title(\"Canny 2 [{}]\".format(i2))\n",
        "        plt.imshow(cv2.cvtColor(edges2, cv2.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "\n",
        "    if show_work:\n",
        "        plt.figure(figsize=(20,20))\n",
        "        plt.subplot(121); plt.title(\"index {} sim_score {}\".format(index, (score*100).round(1), 15), fontsize=20); \n",
        "        plt.imshow(cv2.cvtColor(image1_gray*(mask>0), cv2.COLOR_BGR2RGB))\n",
        "        plt.subplot(122)\n",
        "        plt.imshow(cv2.cvtColor(image2_gray*(mask>0), cv2.COLOR_BGR2RGB))\n",
        "\n",
        "      # prioritize the false negative cases to minimize the false positives \n",
        "    if i1>(i2+(0.01*i2)):\n",
        "        if show_work: plt.title(\"Oggetto in 1\", fontsize=20); plt.show()\n",
        "        print (colored(\"#Oggetto in 1 [{}]\".format(i1-i2),'blue')); return 1;\n",
        "    else:\n",
        "        if show_work: plt.title(\"Oggetto in 2\", fontsize=20); plt.show()\n",
        "        print(colored(\"#Oggetto in 2 [{}]\".format(i2-i1),'blue')); return 2;"
      ],
      "execution_count":8,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "des_recovery = None\n",
        "\n",
        "def warp (prev_show, prev_frame, frame, show_work=False, show_result=False):\n",
        "      # find the keypoints and descriptors with SIFT\n",
        "    global des_recovery\n",
        "    global mean_prev\n",
        "\n",
        "    if not des_recovery is None:\n",
        "        kp1, des1 = des_recovery\n",
        "    else:\n",
        "        kp1, des1 = sift.detectAndCompute(prev_show,None)\n",
        "        des_recovery = (kp1, des1)\n",
        "    kp2, des2 = sift.detectAndCompute(frame,None)\n",
        "    \n",
        "      # determine if camera is static, \n",
        "    if len(kp1)!=0 and len(kp2)!=0:\n",
        "      pp1 = np.array([[int(p.pt[0]),int(p.pt[1])] for p in kp1])\n",
        "      pp2 = np.array([[int(p.pt[0]),int(p.pt[1])] for p in kp2])\n",
        "      matches = int(np.sum((pp1[:,None] == pp2).all(2).any(1))\/len(kp1)*100)\n",
        "      if(matches<THRESH_STATIC_OR_MOVING): # the prev images need warping and old SIFT points are trashed\n",
        "          print( colored(\"Warping\", \"cyan\") )\n",
        "          des_recovery = None\n",
        "      else: # no need to warp\n",
        "          return (prev_show, prev_frame, frame)\n",
        "\n",
        "    matches1 = []; matches1_bg = []\n",
        "    matches2 = []; matches2_bg = []\n",
        "      # match the descriptors and build the corrspondences arrays of good matches\n",
        "    matches_pairs = flann.knnMatch(des1, des2,k=2)\n",
        "    for i,(m,n) in enumerate(matches_pairs):\n",
        "        if m.distance < 0.7*n.distance:\n",
        "            matches1.append(kp1[m.queryIdx].pt)\n",
        "            matches2.append(kp2[m.trainIdx].pt)\n",
        "    matches1 = np.asarray(matches1, np.int32)\n",
        "    matches2 = np.asarray(matches2, np.int32)\n",
        "\n",
        "    if len(matches1)>MIN_MATCH_COUNT:\n",
        "        F, mask = cv2.findFundamentalMat(matches1,matches2,cv2.FM_LMEDS)\n",
        "          # we select only inlier points\n",
        "        matches1 = matches1[mask.ravel()==1]\n",
        "        matches2 = matches2[mask.ravel()==1]\n",
        "\n",
        "          # find epilines corresponding to points in left image (first image) and drawing its lines on right image\n",
        "        lines2 = cv2.computeCorrespondEpilines(matches1.reshape(-1,1,2),1,F)\n",
        "        lines2 = lines2.reshape(-1,3)\n",
        "\n",
        "        if show_work:\n",
        "            img3,img4 = drawlines(prev_show,frame,lines2,matches2,matches1)\n",
        "            plt.figure(figsize=(20,10))\n",
        "            plt.subplot(121); plt.title(\"lines {0} points {1}\".format(len(lines2), len(matches1))); plt.imshow(img3)\n",
        "            plt.subplot(122); plt.imshow(img4)\n",
        "            plt.show()\n",
        "\n",
        "          # keep only points near <1px to an epipolar line\n",
        "        for pt1,pt2 in zip(matches1,matches2):\n",
        "            pixels_err = PIXELS_ERR\n",
        "            for line in lines2:\n",
        "                pixels_err = min(pixels_err,abs(line[0] * pt1[0] + line[1] * pt1[1] + line[2]) \/ np.sqrt((line[0] * line[0]) + (line[1]*line[1])))\n",
        "            if pixels_err<1:\n",
        "                matches1_bg.append(pt1)\n",
        "                matches2_bg.append(pt2)\n",
        "\n",
        "        print(\"bg matches: \",len(matches1_bg),\"\/\",len(matches1))\n",
        "\n",
        "    if len(matches1_bg)>MIN_MATCH_COUNT:\n",
        "          # retrieving perspective homography\n",
        "        src = np.float32(matches1_bg)\n",
        "        dst = np.float32(matches2_bg)\n",
        "        H, masked = cv2.findHomography(src,dst, cv2.RANSAC, 5.0)\n",
        "        dst_show = cv2.warpPerspective(np.uint16(prev_show)+1,H,(prev_frame.shape[1], prev_frame.shape[0]))\n",
        "        dst = cv2.warpPerspective(np.uint16(prev_frame)+1,H,(prev_frame.shape[1], prev_frame.shape[0]))\n",
        "        \n",
        "          # correct the last pixel at margins\n",
        "        dst_show[cv2.dilate(np.uint8(dst_show==0), None)>0]=0\n",
        "        dst[cv2.dilate(np.uint8(dst==0), None)>0]=0\n",
        "\n",
        "          # warp\n",
        "        prev_show = np.uint8(((dst_show-1)*(dst_show>0))+((dst_show<1)*frame))\n",
        "        prev_frame = np.uint8(((dst-1)*(dst>0))+((dst<1)*frame))\n",
        "        mean_prev = [prev_show]\n",
        "\n",
        "        if show_result:\n",
        "            plt.figure(figsize=(20,10))\n",
        "            plt.subplot(121); plt.title.set_text('Left warp')\n",
        "            plt.imshow(cv2.cvtColor(dst,cv2.COLOR_GRAY2RGB))\n",
        "            plt.subplot(122); plt.title.set_text('Compelete prev frame warped')\n",
        "            plt.imshow(cv2.cvtColor(prev_frame,cv2.COLOR_GRAY2RGB))\n",
        "            plt.show()\n",
        "        \n",
        "        return (prev_show, prev_frame, frame)\n",
        "    else:\n",
        "        print( colored(\"Not enough matches are found - {}\/{}\".format(len(matches1_bg), MIN_MATCH_COUNT), \"red\") )\n",
        "        mean_prev = [prev_show]\n",
        "\n",
        "        return None"
      ],
      "execution_count":9,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "**FLOW**"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        " # FLANN parameters\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "search_params = dict(checks=50)\n",
        "sift = cv2.SIFT_create()\n",
        "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
        " # WARP parameters\n",
        "THRESH_STATIC_OR_MOVING = 12 # %\n",
        "PIXELS_ERR = 1\n",
        "MIN_MATCH_COUNT = 10\n",
        " #other parameters\n",
        "sim_thresh = 165\n",
        "min_rect_body_ratio_thresh = 0.005\n",
        "min_rect_thresh = (5, 10)\n",
        "frames_to_skip = 2\n",
        "mean_prev_size = 0\n",
        "show_work = False\n",
        "debug_spot = False\n",
        "show_result = False\n",
        " # iterators\n",
        "index = 0\n",
        "prev_bounds = []\n",
        "frame = None\n",
        "prev_frame = None\n",
        "des_recovery = None\n",
        "output_video = []\n",
        "mean_prev = []\n",
        "           \n",
        "\n",
        "# video_name=files[np.random.randint(0,len(files))]\n",
        "video_name=\"ex\/test.avi\"\n",
        "cap = cv2.VideoCapture(video_name)\n",
        "tot_frames = 0\n",
        "while True:\n",
        "    for _ in range(frames_to_skip): ret, frame_BGR = cap.read() # skip\n",
        "    ret, frame_BGR = cap.read()\n",
        "    if frame_BGR is None: break\n",
        "    tot_frames+=1\n",
        "cap.release()\n",
        "\n",
        "cap = cv2.VideoCapture(video_name)\n",
        "bar = progressbar.ProgressBar(maxval=tot_frames, widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
        "bar.start()\n",
        "# for i in range(100):\n",
        "#     for _ in range(frames_to_skip): ret, frame_BGR = cap.read() # skip\n",
        "#     ret, frame_BGR = cap.read()\n",
        "while True:\n",
        "    for _ in range(frames_to_skip): ret, frame_BGR = cap.read() # skip\n",
        "    ret, frame_BGR = cap.read()\n",
        "    if frame_BGR is None: break\n",
        "    \n",
        "    # restart\n",
        "    start = time.time()\n",
        "    index+=1\n",
        "    prev_frame = frame\n",
        "    frame = cv2.cvtColor(np.uint8(frame_BGR),cv2.COLOR_BGR2GRAY)\n",
        "    if index<2:\n",
        "        min_rect_body_ratio_thresh = (frame.shape[0] * frame.shape[1] ) * min_rect_body_ratio_thresh\n",
        "        prev_show = frame.copy()\n",
        "        mean_prev.append(prev_show.copy())\n",
        "        continue\n",
        "    handle_camera_movement = warp(prev_show, prev_frame, frame)\n",
        "    if handle_camera_movement is None:\n",
        "        frame = prev_frame\n",
        "        continue\n",
        "\n",
        "    prev_show, prev_frame, next_frame = handle_camera_movement\n",
        "\n",
        "    # plt.figure(figsize=(15,10))\n",
        "    # plt.subplot(131); plt.title(\"prev_show\")\n",
        "    # plt.imshow(cv2.cvtColor(np.uint8(cv2.GaussianBlur(next_frame, (1, 1), 0)), cv2.COLOR_GRAY2RGB))\n",
        "    # plt.subplot(132); plt.title(\"next\")\n",
        "    # plt.imshow(cv2.cvtColor(np.uint8(cv2.GaussianBlur(next_frame, (3, 3), 0)), cv2.COLOR_GRAY2RGB))\n",
        "    # plt.subplot(133); plt.title(\"next\")\n",
        "    # plt.imshow(cv2.cvtColor(np.uint8(cv2.GaussianBlur(next_frame, (5, 5), 0)), cv2.COLOR_GRAY2RGB))\n",
        "    # plt.show()\n",
        "    \n",
        "      # identify movement areas in prev_frame to next_frame \n",
        "    (score, sim) = ssim(prev_frame, cv2.GaussianBlur(next_frame, (3, 3), 0), full=True)\n",
        "    sim = np.uint8(sim*255)\n",
        "    thresh = cv2.threshold(sim, sim_thresh, 1, cv2.THRESH_BINARY)[1]\n",
        "    thresh = np.uint8(np.logical_not(thresh))\n",
        "    thresh = cv2.medianBlur(thresh, 11) # remove small pieces\n",
        "    thresh = cv2.morphologyEx(thresh,cv2.MORPH_CLOSE, np.ones((9,9),np.uint8)) # unify pieces\n",
        "\n",
        "    static_area = np.uint8(np.logical_not(thresh))\n",
        "    movement_area = thresh\n",
        "\n",
        "      # get rid of the frame margins\n",
        "    if np.any(movement_area[0,10:-10]) and not np.any(movement_area[10,10:-10]):\n",
        "        movement_area[:10,:] = 0\n",
        "    if np.any(movement_area[-1,10:-10]) and not np.any(movement_area[-10,10:-10]):\n",
        "        movement_area[-10:-1,:] = 0\n",
        "    if np.any(movement_area[10:-10,0]) and not np.any(movement_area[10:-10,10]):\n",
        "        movement_area[:,:10] = 0\n",
        "    if np.any(movement_area[10:-10,-1]) and not np.any(movement_area[10:-10,-10]):\n",
        "        movement_area[:,-10:-1] = 0\n",
        "    \n",
        "      # crete rectangles from countours\n",
        "    rects = []\n",
        "    bounds = []\n",
        "    recovery_bounds = []\n",
        "    contours, hierarchy = cv2.findContours(movement_area,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    bounded_image=movement_area*prev_frame\n",
        "    for c in contours:\n",
        "        x,y,w,h = cv2.boundingRect(c)\n",
        "        if w > min_rect_thresh[0] and h > min_rect_thresh[1]:\n",
        "            m=np.zeros_like(movement_area, np.uint8)\n",
        "            m[y:y+h,x:x+w] = 1\n",
        "            rects.append({\"x\":x,\"y\":y,\"w\":w,\"h\":h,\"m\":m})\n",
        "        \n",
        "    print(\"rects: \", len(rects))\n",
        "\n",
        "      # create indipendent bounds from rectangles\n",
        "    while len(rects)!=0:\n",
        "        x = rects[0][\"x\"];y = rects[0][\"y\"];w = rects[0][\"w\"];h = rects[0][\"h\"]\n",
        "        m = rects[0][\"m\"]\n",
        "        m_expanded = expand_borders(m) \n",
        "        cv2.rectangle(bounded_image,(x,y),(x+w,y+h),(255,255,0),2)\n",
        "        rects.remove(rects[0])\n",
        "\n",
        "        shape_modified = True\n",
        "        while shape_modified:\n",
        "            shape_modified = False\n",
        "            for r_in in rects:\n",
        "                if np.any(np.logical_and(m_expanded, r_in[\"m\"])):\n",
        "                    rects.remove(r_in)\n",
        "                    cv2.rectangle(bounded_image,(r_in[\"x\"],r_in[\"y\"]),(r_in[\"x\"]+r_in[\"w\"],r_in[\"y\"]+r_in[\"h\"]),(115,115,0),1)\n",
        "                    m[r_in[\"y\"]:r_in[\"y\"]+r_in[\"h\"],r_in[\"x\"]:r_in[\"x\"]+r_in[\"w\"]] = 1\n",
        "                    shape_modified = True\n",
        "                    break\n",
        "        bounds.append(m)\n",
        "\n",
        "    print(\"bounds: \", len(bounds))\n",
        "\n",
        "      # get rid of the distorsion due to low movement or stopping object\n",
        "    for prev_bound in prev_bounds:\n",
        "        movement_zones = []\n",
        "        for idx_bound in range(len(bounds)):\n",
        "            if np.array_equal(np.logical_and(prev_bound, bounds[idx_bound]), prev_bound):\n",
        "                movement_zones.append(idx_bound)\n",
        "        if len(movement_zones)>=10: # (ignore it) push forward the previous bound to the next round\n",
        "            for idx_zone in reversed(movement_zones):\n",
        "                bounds.pop(idx_zone)\n",
        "            recovery_bounds.append(prev_bound)\n",
        "        elif len(movement_zones)>=2: # (use it) group and add the rectangle\n",
        "            canvas = np.zeros(movement_area.shape)\n",
        "            \n",
        "            for idx_bound in reversed(movement_zones):\n",
        "                canvas[bounds[idx_bound]>0] = 1\n",
        "                bounds.pop(idx_bound)\n",
        "\n",
        "            (y, x) = np.where(canvas == 1)\n",
        "            (topy, topx) = (np.min(y), np.min(x))\n",
        "            (bottomy, bottomx) = (np.max(y), np.max(x))\n",
        "            cv2.rectangle(bounded_image,(topx,topy),(bottomx,bottomy),(115,115,0),3)\n",
        "            canvas[topx:bottomx+1, topy:bottomy+1] = 1\n",
        "            bounds.append(canvas)\n",
        "\n",
        "      # improvement areas \n",
        "    a = [] # areas to ignore into zone [prev_bounds - next_bounds]. The remaining is updated with next_frame\n",
        "    b = [] # areas to update into zone [next_bounds - prev_bounds]. Update with prev_frame\n",
        "    recover_prev_bound = [0]*len(prev_bounds)\n",
        "    if not(prev_bounds is None) or len(prev_bounds) != 0:\n",
        "        for bound in bounds:\n",
        "            a_current = []\n",
        "            b_current = []\n",
        "            recover_current_bound = []\n",
        "            for prev_bound_id,prev_bound in enumerate(prev_bounds):\n",
        "                if (np.sum(prev_bound[bound==1])\/np.sum(bound))>0.5 or (np.sum(bound[prev_bound==1])\/np.sum(prev_bound))>0.5:\n",
        "                    print(\"--cycle-- bound matching\")\n",
        "                    if np.any(np.logical_and(prev_bound, bound)):\n",
        "                        print(\"crossing\")\n",
        "\n",
        "                        static_prev_zone = np.uint8(np.logical_and(prev_bound, np.logical_not(bound)))\n",
        "                        moving_next_zone = np.logical_and(np.logical_not(prev_bound), bound)\n",
        "                        # if not np.all(prev_bound[bound==1]) and not np.all(bound[prev_bound==1]):\n",
        "                        if np.any(static_prev_zone) and np.any(moving_next_zone):\n",
        "                            imm = spot_the_diff(static_prev_zone*prev_show, static_prev_zone*next_frame, log=True, show_work=show_work, debug_init=debug_spot)\n",
        "                            print(\"is moving\")\n",
        "                            if imm == 0 or imm == 1: # (update) images equality or obj residual in prev_show \n",
        "                                a_current.append(bound)\n",
        "                                b.append(np.uint8(np.logical_not(moving_next_zone)))\n",
        "                                recover_current_bound.append(bound)\n",
        "                            else: # (ignore it) probably the bound wasn't recognized properly\n",
        "                                area_to_ignore = np.uint8(np.logical_or(prev_bound,bound))\n",
        "                                a_current.append(area_to_ignore)\n",
        "                                recover_current_bound.append(area_to_ignore)\n",
        "                        elif np.any(static_prev_zone):\n",
        "                            imm = spot_the_diff(static_prev_zone*prev_show, static_prev_zone*next_frame, log=True, show_work=show_work, debug_init=debug_spot)\n",
        "                            print(\"is getting smaller\")\n",
        "                            if imm == 0 or imm == 1: # (update) \n",
        "                                print(\"and there is good stuff\")\n",
        "                                a_current.append(bound)\n",
        "                                recover_current_bound.append(bound)\n",
        "                            else:\n",
        "                                a_current.append(prev_bound) # (ignore it)\n",
        "                                recover_current_bound.append(prev_bound)\n",
        "                        else:\n",
        "                            print(\"is getting bigger\")\n",
        "                            a_current.append(bound) # (ignore it)\n",
        "                            recover_current_bound.append(bound)\n",
        "            if len(a_current)>0:\n",
        "                # plt.figure(figsize=(20,10))\n",
        "                a_all = np.all(a_current, axis=0)\n",
        "                a.append(a_all)\n",
        "                # plt.subplot(131); plt.title(\"a\")\n",
        "                # plt.imshow(cv2.cvtColor(np.uint8(a_all*next_frame), cv2.COLOR_GRAY2RGB))\n",
        "                if len(b_current)>0:\n",
        "                    b_all = np.all(b_current, axis=0)\n",
        "                    b.append(np.logical_and(np.logical_not(a_all), b_all))\n",
        "                    # plt.subplot(132); plt.title(\"b\")\n",
        "                    # plt.imshow(cv2.cvtColor(np.uint8(b_all*prev_frame), cv2.COLOR_GRAY2RGB))\n",
        "            if len(recover_current_bound)>0:\n",
        "                rec_all = np.all(recover_current_bound, axis=0) \n",
        "                contours, hierarchy = cv2.findContours(np.uint8(rec_all),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "                if len(contours)>1:\n",
        "                    for idx in range(len(contours)):\n",
        "                        canvas = np.zeros_like(next_frame, np.uint8)\n",
        "                        cv2.drawContours(canvas, contours, idx, 1, -1)\n",
        "                        recovery_bounds.append(canvas)\n",
        "                else:\n",
        "                    recovery_bounds.append(rec_all)\n",
        "            #     plt.subplot(133); plt.title(\"rec {}\".format(len(contours)))\n",
        "            #     plt.imshow(cv2.cvtColor(np.uint8(rec_all)*255, cv2.COLOR_GRAY2RGB))\n",
        "            # plt.show()\n",
        "            \n",
        "            # do we need to perform an additional check when the static_prev_area is divided in two and\n",
        "            # (probably) spot the diff fail and return 1? under here is the code for that case \n",
        "            # if len(accros_bound)>0:\n",
        "            #     # unify to not have duplicates\n",
        "            #     canvas = np.zeros_like(next_frame, np.uint8)\n",
        "            #     for idx in range(len(accros_bound)):\n",
        "            #         cv2.drawContours(canvas, accros_bound, idx, 1, -1)\n",
        "            #     contours, hierarchy = cv2.findContours(canvas,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "            #     for idx in range(len(contours)):\n",
        "            #         canvas = np.zeros_like(next_frame, np.uint8)\n",
        "            #         cv2.drawContours(canvas, contours, idx, 1, -1)\n",
        "            #         (y, x) = np.where(canvas == 1)\n",
        "            #         (topy, topx) = (np.min(y), np.min(x))\n",
        "            #         (bottomy, bottomx) = (np.max(y), np.max(x))\n",
        "            #         if (np.sum(canvas)>min_rect_body_ratio_thresh) and (bottomx-topx) > min_rect_thresh[0] and (bottomy-topy) > min_rect_thresh[1] :\n",
        "            #             bounds.append(canvas)\n",
        "            # if recover_bound: recovery_bounds.append(bound)\n",
        "\n",
        "    if show_result:\n",
        "        plt.figure(figsize=(20,10))\n",
        "        plt.subplot(131); plt.title(\"Static area estim\")\n",
        "        plt.imshow(cv2.cvtColor(np.uint8(static_area*next_frame), cv2.COLOR_GRAY2RGB))\n",
        "        plt.subplot(132); plt.title(\"Movement area estim\")\n",
        "        plt.imshow(cv2.cvtColor(np.uint8(movement_area*prev_frame), cv2.COLOR_GRAY2RGB))\n",
        "\n",
        "        # apply good static pixels\n",
        "    for old_zone in b:\n",
        "        prev_show[old_zone>0]=(old_zone*prev_show)[old_zone>0]\n",
        "    for non_static_zone in a:\n",
        "        static_area[non_static_zone>0] = 0\n",
        "    if len(a)>0: prev_show[static_area>0]=(static_area*next_frame)[static_area>0]\n",
        "\n",
        "    if show_result:\n",
        "        plt.subplot(132); plt.title(\"Bounds\")\n",
        "        plt.imshow(cv2.cvtColor(np.uint8(bounded_image), cv2.COLOR_GRAY2RGB))\n",
        "        plt.title(\"Show\")\n",
        "        plt.subplot(133); plt.imshow(cv2.cvtColor(np.uint8(prev_show), cv2.COLOR_GRAY2RGB))\n",
        "        plt.show()\n",
        "        \n",
        "    mean_prev.append(prev_show.copy())\n",
        "    if len(mean_prev)>mean_prev_size:\n",
        "        mean_prev.pop(0)\n",
        "\n",
        "    output_video.append(np.hstack([frame.copy(),np.mean(mean_prev, axis=0).copy() if mean_prev_size>0 else prev_show.copy()]))\n",
        "    \n",
        "    #log\n",
        "    print(colored(\"bounds: {0} - prev_bounds: {1} - recovery_bounds: {2}\".format(len(bounds),len(prev_bounds),len(recovery_bounds)),\"yellow\"))\n",
        "    print(colored(\"time: {}\".format(time.time()-start),\"yellow\"))\n",
        "    print()\n",
        "    \n",
        "    #restart\n",
        "    prev_bounds = recovery_bounds if len(prev_bounds) > 0 else bounds # ERR\n",
        "    bar.update((index-1)+1)\n",
        "\n",
        "cap.release()\n",
        "bar.finish()\n",
        "out = cv2.VideoWriter('project.avi',cv2.VideoWriter_fourcc(*'DIVX'), 30, (frame.shape[1]*2,frame.shape[0]))\n",
        " \n",
        "for i in range(len(output_video)):\n",
        "    out.write(cv2.cvtColor(np.uint8(output_video[i]), cv2.COLOR_GRAY2RGB))\n",
        "    out.write(cv2.cvtColor(np.uint8(output_video[i]), cv2.COLOR_GRAY2RGB))\n",
        "out.release()"
      ],
      "execution_count":18,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# **########################## DEBUG ##############################**"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "spot_the_diff(good_zone*prev_show, good_zone*next_frame, True, True)"
      ],
      "execution_count":0,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "res1 = spot_the_diff(cv2.cvtColor(cv2.imread('spot_debug\/prev_15.jpg'), cv2.COLOR_BGR2GRAY), cv2.cvtColor(cv2.imread('spot_debug\/next_15.jpg'), cv2.COLOR_BGR2GRAY), True)\n",
        "print(colored('no', 'red')) if(res1!=2) else print(colored('ok', 'green'))"
      ],
      "execution_count":82,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Debug bound creation\n",
        "\n",
        "<!-- plt.figure(figsize=(10,10))\n",
        "plt.subplot(161)\n",
        "plt.imshow(cv2.cvtColor(np.uint8((bounds[20]>0)*255), cv2.COLOR_GRAY2RGB))\n",
        "plt.subplot(162)\n",
        "plt.imshow(cv2.cvtColor(np.uint8((bounds[21]>0)*255), cv2.COLOR_GRAY2RGB))\n",
        "plt.subplot(163)\n",
        "plt.imshow(cv2.cvtColor(np.uint8((bounds[22]>0)*255), cv2.COLOR_GRAY2RGB))\n",
        "plt.subplot(164)\n",
        "plt.imshow(cv2.cvtColor(np.uint8((bounds[23]>0)*255), cv2.COLOR_GRAY2RGB))\n",
        "plt.subplot(165)\n",
        "plt.imshow(cv2.cvtColor(np.uint8((bounds[24]>0)*255), cv2.COLOR_GRAY2RGB))\n",
        "plt.subplot(166)\n",
        "plt.imshow(cv2.cvtColor(np.uint8((bounds[25]>0)*255), cv2.COLOR_GRAY2RGB))\n",
        "plt.show()\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(141)\n",
        "plt.imshow(cv2.cvtColor(np.uint8((prev_bounds[0]>0)*255), cv2.COLOR_GRAY2RGB))\n",
        "plt.subplot(142)\n",
        "plt.imshow(cv2.cvtColor(np.uint8((prev_bounds[1]>0)*255), cv2.COLOR_GRAY2RGB))\n",
        "plt.subplot(143)\n",
        "plt.imshow(cv2.cvtColor(np.uint8((prev_bounds[2]>0)*255), cv2.COLOR_GRAY2RGB))\n",
        "plt.subplot(144)\n",
        "plt.imshow(cv2.cvtColor(np.uint8((prev_bounds[3]>0)*255), cv2.COLOR_GRAY2RGB))\n",
        "plt.show()\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(141)\n",
        "plt.imshow(cv2.cvtColor(np.uint8((recovery_bounds[0]>0)*255), cv2.COLOR_GRAY2RGB))\n",
        "plt.subplot(142)\n",
        "plt.imshow(cv2.cvtColor(np.uint8((recovery_bounds[1]>0)*255), cv2.COLOR_GRAY2RGB))\n",
        "plt.subplot(143)\n",
        "plt.imshow(cv2.cvtColor(np.uint8((recovery_bounds[2]>0)*255), cv2.COLOR_GRAY2RGB))\n",
        "plt.subplot(144)\n",
        "plt.imshow(cv2.cvtColor(np.uint8((recovery_bounds[3]>0)*255), cv2.COLOR_GRAY2RGB))\n",
        "plt.show() -->"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### **########################################### TEST AND BACKUP ################################################**"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Test `spot_the_diff`\n",
        "\n",
        "<!-- res1 = spot_the_diff(cv2.cvtColor(cv2.imread('spot\/1_2.png'), cv2.COLOR_BGR2GRAY), cv2.cvtColor(cv2.imread('spot\/1.png'), cv2.COLOR_BGR2GRAY))\n",
        "res4 = spot_the_diff(cv2.cvtColor(cv2.imread('spot\/prev_low_thresh.jpg'), cv2.COLOR_BGR2GRAY), cv2.cvtColor(cv2.imread('spot\/next_low_thresh.jpg'), cv2.COLOR_BGR2GRAY))\n",
        "res5 = spot_the_diff(cv2.cvtColor(cv2.imread('spot\/prev_high_thresh.jpg'), cv2.COLOR_BGR2GRAY), cv2.cvtColor(cv2.imread('spot\/next_high_thresh.jpg'), cv2.COLOR_BGR2GRAY))\n",
        "res6 = spot_the_diff(cv2.cvtColor(cv2.imread('spot_debug\/prev_1.jpg'), cv2.COLOR_BGR2GRAY), cv2.cvtColor(cv2.imread('spot_debug\/next_1.jpg'), cv2.COLOR_BGR2GRAY))\n",
        "res7 = spot_the_diff(cv2.cvtColor(cv2.imread('spot_debug\/next_2.jpg'), cv2.COLOR_BGR2GRAY), cv2.cvtColor(cv2.imread('spot_debug\/prev_2.jpg'), cv2.COLOR_BGR2GRAY))\n",
        "res8 = spot_the_diff(cv2.cvtColor(cv2.imread('spot_debug\/next_3.jpg'), cv2.COLOR_BGR2GRAY), cv2.cvtColor(cv2.imread('spot_debug\/prev_3.jpg'), cv2.COLOR_BGR2GRAY))\n",
        "res9 = spot_the_diff(cv2.cvtColor(cv2.imread('spot_debug\/next_4.jpg'), cv2.COLOR_BGR2GRAY), cv2.cvtColor(cv2.imread('spot_debug\/prev_4.jpg'), cv2.COLOR_BGR2GRAY))\n",
        "res10 = spot_the_diff(cv2.cvtColor(cv2.imread('spot_debug\/next_5.jpg'), cv2.COLOR_BGR2GRAY), cv2.cvtColor(cv2.imread('spot_debug\/prev_5.jpg'), cv2.COLOR_BGR2GRAY))\n",
        "print(colored('no', 'red')) if(res1!=1) else print(colored('ok', 'green'))\n",
        "print(colored('no', 'red')) if(res1!=2) else print(colored('ok', 'green'))\n",
        "print(colored('no', 'red')) if(res4!=1) else print(colored('ok', 'green'))\n",
        "print(colored('no', 'red')) if(res5!=1) else print(colored('ok', 'green'))\n",
        "print(colored('no', 'red')) if(res6!=1) else print(colored('ok', 'green'))\n",
        "print(colored('no', 'red')) if(res7!=1) else print(colored('ok', 'green'))\n",
        "print(colored('no', 'red')) if(res8!=1) else print(colored('ok', 'green'))\n",
        "print(colored('no', 'red')) if(res9!=1) else print(colored('ok', 'green'))\n",
        "print(colored('no', 'red')) if(res10!=2) else print(colored('ok', 'green'))\n",
        "\n",
        "\n",
        "# image1 = cv2.imread('12118.png')\n",
        "# image2 = cv2.imread('12118_2.png')\n",
        "# image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "# image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# image1_gray=good_zone*prev_show\n",
        "# image2_gray=good_zone*next_frame\n",
        "# spot_the_diff(good_zone*prev_show, good_zone*next_frame) -->\n"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Backup `spot_the_diff`\n",
        "<!-- index = 0\n",
        "\n",
        "def spot_the_diff(image1_gray, image2_gray, log=False, show_work=True, debug_init=True):\n",
        "    global index\n",
        "\n",
        "    if debug_init:\n",
        "        plt.figure(figsize=(20,20))\n",
        "        plt.subplot(121); plt.title(\"Spot prev\", fontsize=20)\n",
        "        plt.imshow(cv2.cvtColor(image1_gray, cv2.COLOR_BGR2RGB))\n",
        "        plt.subplot(122); plt.title(\"Spot next\", fontsize=20)\n",
        "        plt.imshow(cv2.cvtColor(image2_gray, cv2.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "\n",
        "      # first i use a distance low\n",
        "    dif = cv2.absdiff(image1_gray, image2_gray)\n",
        "    a = cv2.threshold(dif, 50, 255, cv2.THRESH_BINARY)[1]\n",
        "    a = cv2.medianBlur(a, 7)\n",
        "\n",
        "    if not np.any(a):\n",
        "        print(colored(\"Equality\", 'blue'))\n",
        "        return 0\n",
        "    index = 0\n",
        "    plt.imsave(\"spot_debug\/prev_{}.jpg\".format(index),cv2.cvtColor(image1_gray, cv2.COLOR_BGR2RGB))\n",
        "    plt.imsave(\"spot_debug\/next_{}.jpg\".format(index),cv2.cvtColor(image2_gray, cv2.COLOR_BGR2RGB))\n",
        "    detected = ((np.sum(a>0)\/np.sum(image1_gray>0))*100).round(3)\n",
        "\n",
        "    if(detected<30):\n",
        "        if log: print(\"Not, \",detected)\n",
        "        detected=0 \n",
        "        adaptive=0\n",
        "        thresh = max_distance(image1_gray, image2_gray)\n",
        "        while(detected<25 or detected>65):\n",
        "            a = np.uint8(thresh>adaptive)*255\n",
        "            detected = ((np.sum(a>0)\/np.sum(image1_gray>0))*100).round(3)\n",
        "            if log: print(\"Not, \",detected)\n",
        "            adaptive+=5\n",
        "        a = cv2.erode(cv2.medianBlur(a, 21), np.ones((6,6),np.uint))\n",
        "    else:\n",
        "        adaptive=-1\n",
        "        a = cv2.medianBlur(a, 15)\n",
        "\n",
        "    detected = ((np.sum(a>0)\/np.sum(image1_gray>0))*100).round(3)\n",
        "    print(colored(\"#Detected count {0}% {1} \".format(detected, \"absdiff\" if adaptive<0 else adaptive-5),'blue'))\n",
        "    if show_work:\n",
        "        plt.figure(figsize=(20,20))\n",
        "        plt.subplot(131); plt.title(\"Mask\")\n",
        "        plt.imshow(cv2.cvtColor(np.uint8(a), cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # #contours,hierarchy = cv2.findContours(np.uint8(a), cv2.RETR_EXTERNAL, 1)\n",
        "    # #p = np.zeros(image1_gray.shape)\n",
        "    # #[cv2.drawContours(p, i, -1, (255),1) for i in contours]\n",
        "\n",
        "    # #p = cv2.Canny(a,100,200)\n",
        "    # #p = cv2.approxPolyDP(contours, 0.1*cv2.arcLength(contours,True), True)\n",
        "\n",
        "    mask1 = cv2.morphologyEx(a,cv2.MORPH_CLOSE, np.ones((9,9),np.uint8))\n",
        "    mask = cv2.morphologyEx(mask1, cv2.MORPH_GRADIENT, np.ones((6,6),np.uint8))\n",
        "    if show_work:\n",
        "        plt.subplot(132); plt.title(\"Mask closed\")\n",
        "        plt.imshow(cv2.cvtColor(np.uint8(mask1), cv2.COLOR_BGR2RGB))\n",
        "        plt.subplot(133); plt.title(\"Mask gradient\")\n",
        "        plt.imshow(cv2.cvtColor(np.uint8(mask), cv2.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "\n",
        "    # #mask = cv2.fillPoly(np.uint8(a), contours, 255) #-p\n",
        "    # #mask = cv2.floodFill(np.uint8(a),np.uint8(a), 255, 5, 5, flags=cv2.FLOODFILL_MASK_ONLY) #-p\n",
        "\n",
        "      # canny in the border of the movement areas\n",
        "    edges = cv2.Canny(image1_gray*(mask>0),25,70)\n",
        "    edges2 = cv2.Canny(image2_gray*(mask>0),30,90)\n",
        "\n",
        "    if show_work:\n",
        "        plt.figure(figsize=(20,20))\n",
        "        plt.subplot(121)\n",
        "        plt.title(\"canny 1\")\n",
        "        plt.imshow(cv2.cvtColor(edges, cv2.COLOR_BGR2RGB))\n",
        "        plt.subplot(122)\n",
        "        plt.title(\"canny 2\")\n",
        "        plt.imshow(cv2.cvtColor(edges2, cv2.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "\n",
        "      # count of canny oriented pixels in the border of the movement areas \n",
        "    i1=count_oriented(edges)\n",
        "    i2=count_oriented(edges2)\n",
        "    if log: print(i1)\n",
        "    if log: print(i2)\n",
        "\n",
        "    if show_work:\n",
        "        plt.figure(figsize=(20,20))\n",
        "        plt.subplot(121)\n",
        "        plt.imshow(cv2.cvtColor(image1_gray*(mask>0), cv2.COLOR_BGR2RGB))\n",
        "        plt.subplot(122)\n",
        "        plt.imshow(cv2.cvtColor(image2_gray*(mask>0), cv2.COLOR_BGR2RGB))\n",
        "\n",
        "      # prioritize the false negative cases to minimize the false positives \n",
        "    if i1>(i2+(0.01*i2)):\n",
        "        if show_work: plt.title(\"Oggetto in 1\", fontsize=20); plt.show()\n",
        "        print (colored(\"#Oggetto in 1\",'blue')); return 1;\n",
        "    else:\n",
        "        if show_work: plt.title(\"Oggetto in 2\", fontsize=20); plt.show()\n",
        "        print(colored(\"#Oggetto in 2\",'blue')); return 2; -->"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Backup improvement areas\n",
        "<!-- # improvement areas \n",
        "    a = [] # areas to ignore into zone [prev_bounds - next_bounds]. The remaining is updated with next_frame\n",
        "    b = [] # areas to update into zone [next_bounds - prev_bounds]. Update with prev_frame\n",
        "    recover_prev_bound = [0]*len(prev_bounds)\n",
        "    if not(prev_bounds is None) or len(prev_bounds) != 0:\n",
        "        for bound in bounds:\n",
        "            accros_bound = []\n",
        "            recover_bound = False\n",
        "            for prev_bound_id,prev_bound in enumerate(prev_bounds):\n",
        "                if (np.sum(prev_bound[bound==1])\/np.sum(bound))>0.5 or (np.sum(bound[prev_bound==1])\/np.sum(prev_bound))>0.5:\n",
        "                    print(\"--cycle-- bound matching\")\n",
        "                    if np.any(np.logical_and(prev_bound, bound)):\n",
        "                        print(\"crossing\")\n",
        "\n",
        "                        static_prev_zone = np.uint8(np.logical_and(prev_bound, np.logical_not(bound)))\n",
        "                        # if not np.all(prev_bound[bound==1]) and not np.all(bound[prev_bound==1]):\n",
        "                        if np.any(static_prev_zone) and np.any(np.logical_and(np.logical_not(prev_bound), bound)):\n",
        "                            imm = spot_the_diff(static_prev_zone*prev_show, static_prev_zone*next_frame, log=True)\n",
        "                            print(\"is moving\")\n",
        "                            if imm == 0 or imm == 1: # (update) images equality or obj residual in prev_show \n",
        "                                a.append(bound)\n",
        "                                b.append(np.uint8(np.logical_not(static_prev_zone)))\n",
        "                                contours, hierarchy = cv2.findContours(static_prev_zone,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "                                if len(contours)>1: accros_bound += contours\n",
        "                                else: recover_bound = True\n",
        "                            else: # (ignore it) probably the bound wasn't recognized properly\n",
        "                                area_to_ignore = np.uint8(np.logical_or(prev_bound,bound))\n",
        "                                a.append(area_to_ignore)\n",
        "                                recovery_bounds.append(area_to_ignore)\n",
        "                                recover_prev_bound[prev_bound_id]=1\n",
        "                        elif np.any(static_prev_zone):\n",
        "                            imm = spot_the_diff(static_prev_zone*next_frame, static_prev_zone*prev_show, log=True)\n",
        "                            print(\"is getting smaller\")\n",
        "                            if imm == 0 or imm == 1: # (update) \n",
        "                                print(\"and there is good stuff\")\n",
        "                                if recover_prev_bound[prev_bound_id] != 1:\n",
        "                                    a.append(bound)\n",
        "                                recover_bound = True\n",
        "                            elif recover_prev_bound[prev_bound_id] != 1:\n",
        "                                a.append(prev_bound) # (ignore it)\n",
        "                                recovery_bounds.append(prev_bound)\n",
        "                                recover_prev_bound[prev_bound_id]=1\n",
        "                        else:\n",
        "                            print(\"is getting bigger\")\n",
        "                            a.append(bound) # (ignore it)\n",
        "                            recover_bound = True\n",
        "            if len(accros_bound)>0:\n",
        "                # unify to not have duplicates\n",
        "                canvas = np.zeros_like(next_frame, np.uint8)\n",
        "                for idx in range(len(accros_bound)):\n",
        "                    cv2.drawContours(canvas, accros_bound, idx, 1, -1)\n",
        "                contours, hierarchy = cv2.findContours(canvas,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "                for idx in range(len(contours)):\n",
        "                    canvas = np.zeros_like(next_frame, np.uint8)\n",
        "                    cv2.drawContours(canvas, contours, idx, 1, -1)\n",
        "                    (y, x) = np.where(canvas == 1)\n",
        "                    (topy, topx) = (np.min(y), np.min(x))\n",
        "                    (bottomy, bottomx) = (np.max(y), np.max(x))\n",
        "                    if (np.sum(canvas)>min_rect_body_ratio_thresh) and (bottomx-topx) > min_rect_thresh[0] and (bottomy-topy) > min_rect_thresh[1] :\n",
        "                        bounds.append(canvas)\n",
        "            if recover_bound: recovery_bounds.append(bound) -->"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Time test\n",
        "\n",
        "<!-- start = time.time()\n",
        "for _ in range(10000):\n",
        "    a = np.logical_and(prev_bound, np.logical_not(bound));\n",
        "    np.any(a) and np.any(np.logical_and(np.logical_not(prev_bound), bound)) \n",
        "print(time.time()- start)\n",
        "start = time.time()\n",
        "for _ in range(10000):\n",
        "    a = np.logical_and(prev_bound, np.logical_not(bound));\n",
        "    not np.all(prev_bound[bound==1]) and not np.all(bound[prev_bound==1])\n",
        "print(time.time()- start)\n",
        "start = time.time()\n",
        "for _ in range(10000):\n",
        "    a = np.logical_and(prev_bound, np.logical_not(bound));\n",
        "    not np.all(prev_bound[bound==1]) and np.any(a) \n",
        "print(time.time()- start) -->"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "A matrix\n",
        "\n",
        "<!-- a = np.array([\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "])\n",
        "a[5:6,8:10] = 1\n",
        "\n",
        "np.uint8(np.logical_not(a)) -->"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "If old backup `code`\n",
        "<!-- #--------------------------------------\n",
        "#                     if not np.logical_and(np.all(np.any(accros, axis=0)[np.any(prev_bound, axis=0)]), np.all(np.any(accros, axis=1)[np.any(prev_bound, axis=1)])):\n",
        "#                         div1 = accros.copy()\n",
        "#                         div2 = accros.copy()\n",
        "#                         if not np.all(np.any(accros, axis=0)[np.any(prev_bound, axis=0)]):\n",
        "#                             col = np.argmin(prev_bound, axis=0)]) np.argmin(np.any(accros, axis=0)[np.any(prev_bound, axis=0)])\n",
        "#                             div1[:,0:col] = 0\n",
        "#                             div2[:,col:] = 0\n",
        "#                         else:\n",
        "#                             row = np.argmin(np.any(accros, axis=1)[np.any(prev_bound, axis=1)])\n",
        "#                             div1[0:row,:] = 0\n",
        "#                             div2[row:,:] = 0\n",
        "#                         bounds.append(div1)\n",
        "#                         bounds.append(div2)\n",
        "#--------------------------------------\n",
        "#                     if (((r_in[\"x\"] >= x and r_in[\"x\"] <= x+w) or (r_in[\"x\"]+r_in[\"w\"] >= x and r_in[\"x\"]+r_in[\"w\"] <= x+w))\\\n",
        "#                     and ((r_in[\"y\"] >= y and r_in[\"y\"] <= y+h) or (r_in[\"y\"]+r_in[\"h\"] >= y and r[\"y\"]+r_in[\"h\"] <= y+h))):\n",
        "#--------------------------------------\n",
        "#       min_y = np.int(np.argmax(canvas)\/canvas.shape[1])\n",
        "#       max_y = canvas.shape[0]-np.int(np.argmax(np.flip(canvas))\/canvas.shape[1])\n",
        "#       min_x = np.int(np.argmax(np.transpose(canvas))\/canvas.shape[0])\n",
        "#       max_x = canvas.shape[1]-np.int(np.argmax(np.transpose(np.flip(canvas)))\/canvas.shape[0])\n",
        "#-------------------------------------- -->"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Frames to video `code`\n",
        "<!-- out = cv2.VideoWriter('ex\/lightonoff.avi',cv2.VideoWriter_fourcc(*'DIVX'), 30, (320, 240))\n",
        "for i in range(1000,5001):\n",
        "    name = 'image0{}.jpg'.format(i)\n",
        "    imm = cv2.cvtColor(cv2.imread(name), cv2.COLOR_BGR2GRAY)\n",
        "    out.write(cv2.cvtC\n",
        "-->\n",
        "Video for mean purpose\n",
        "<!-- mean_prev=[]\n",
        "output_video=[]\n",
        "cap = cv2.VideoCapture(\"project.avi\")\n",
        "while True:\n",
        "    ret, frame_BGR = cap.read()\n",
        "    if frame_BGR is None: break\n",
        "    frame = cv2.cvtColor(np.uint8(frame_BGR),cv2.COLOR_BGR2GRAY)\n",
        "    real = frame[:frame.shape[0],:np.int(frame.shape[1]\/2)]\n",
        "    frame_mean = frame[:frame.shape[0],np.int(frame.shape[1]\/2):]\n",
        "    mean_prev.append(frame_mean.copy())\n",
        "    if len(mean_prev)>5:\n",
        "        mean_prev.pop(0)\n",
        "\n",
        "    output_video.append(np.hstack([real.copy(),np.mean(mean_prev, axis=0).copy() if len(mean_prev)>1 else frame_mean.copy()]))\n",
        "cap.release() -->"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### **############################################### FAILS #######################################################**"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "**This is the wrong attempt counting the edges on the base of the orientation degree**\n",
        "\n",
        "<!-- def count_oriented(img, show=False):\n",
        "    # sobel derivatives\n",
        "  derivX = cv2.Sobel(img, cv2.CV_32F, 1, 0)\n",
        "  derivY = cv2.Sobel(img, cv2.CV_32F, 0, 1)\n",
        "  \n",
        "    # orientation and magnitude\n",
        "  orienXY = cv2.phase(derivX, derivY, angleInDegrees=True)\n",
        "  orienYX = cv2.phase(derivY, derivX, angleInDegrees=True)\n",
        "  mag = cv2.magnitude(derivX, derivY)\n",
        "  \n",
        "    # thresholding of the magnitude values\n",
        "  thresh = 50\n",
        "  _, mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)\n",
        "  \n",
        "  if show:\n",
        "      # set the colors\n",
        "    red = np.asarray([0, 0, 255])\n",
        "    cyan = np.asarray([255, 255, 0])\n",
        "    green = np.asarray([0, 255, 0])\n",
        "    yellow = np.asarray([0, 255, 255])\n",
        "\n",
        "      # use np.uint8 required from OpenCV\n",
        "    image_map = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
        "\n",
        "      # it checks that magnitude is above the threshold and that the orientation is in range\n",
        "    image_map[ (mask == 255) & ((orienXY < 90) | (orienYX < 90))] = red\n",
        "    # image_map[(mask == 255) & (((orienXY > 90) & (orienXY < 180)) | ((orienYX > 90) & (orienYX < 180)))] = cyan\n",
        "    # image_map[(mask == 255) &  (((orienXY > 180) & (orienXY < 270)) | ((orienYX > 180) & (orienYX < 270)))] = green\n",
        "    image_map[(mask == 255) & ((orienXY > 270) | (orienYX > 270))] = yellow\n",
        "\n",
        "    plt.figure(figsize=(15,10)); plt.title(\"Mask magnitude min: {} max: {}\".format(np.int(np.min(mag[mag>0])), np.int(np.max(mag))))\n",
        "    plt.imshow(cv2.cvtColor(mask*255, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "  \n",
        "  return np.sum((mask == 255) & ((orienXY < 90) | (orienXY > 270) | (orienYX < 90) | (orienYX > 270))) -->"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "**This is the wrong attempt working on the moving shape - (PIC approach) Quantization of the pixels of the moving shape or of the full frame**\n",
        "\n",
        "<!--\n",
        "frameDelta = np.float32(cv2.absdiff(np.int32(prev_frame),np.int32(next_frame)))\n",
        "thresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]\n",
        "thresh = cv2.dilate(cv2.medianBlur(thresh, 5), None, iterations=2)\n",
        "bin_size = 5\n",
        "shit = np.zeros(summed.shape)\n",
        "for i in range(summed.shape[0]):\n",
        "    for j in range(summed.shape[1]):\n",
        "        if summed[i,j]:\n",
        "            lst = [a[\"prev_pos\"][i,j] for a in bins]\n",
        "            histo, bin_seg = np.histogram(lst, bins=int(255\/bin_size),range=[0,255])\n",
        "            lb_bin = bin_seg[histo.argmax()]\n",
        "            histo, bin_seg = np.histogram(histo, bins=bin_size-1,range=[lb_bin,lb_bin+bin_size-1])\n",
        "            shit[i,j]=bin_seg[histo.argmax()]\n",
        "plt.imshow(cv2.cvtColor(np.uint8(shit),cv2.COLOR_GRAY2RGB))\n",
        "-->"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "**This is the wrong attempt working on the moving shape - (Mean and Median) interpolation of past frames through mean or median**\n",
        "\n",
        "<!--\n",
        "bg = []\n",
        "idx = 0\n",
        "# Initialize the background image\n",
        "for at in range(10+num_frame_bg):\n",
        "    ret, frame = cap.read()\n",
        "    if ret and not frame is None:\n",
        "        idx += 1\n",
        "        frame = frame.astype(float)\n",
        "        if idx > num_frame_bg:\n",
        "\n",
        "            # Finding the background as the mean or median of first n frames\n",
        "            wbg= bg*idx\n",
        "            bg_interpolated = np.stack(wbg+[frame], axis=0)\n",
        "            bg_interpolated = interpolation(bg_interpolated, axis=0)\n",
        "\n",
        "            #plt.title(\"Background\")\n",
        "            #plt.imshow(cv2.cvtColor(bg_interpolated.astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
        "            #plt.show()\n",
        "\n",
        "            ## Calculating a TFD\n",
        "            #two_frame_difference(frame, bg_interpolated, distance, threshold)\n",
        "\n",
        "            # Background subtraction\n",
        "            mask = distance(frame, prev_frame) > threshold\n",
        "            display_image_and_mask(bg_interpolated, mask)\n",
        "            \n",
        "            bg.pop(0)\n",
        "            bg.append(bg_interpolated)\n",
        "        else:\n",
        "            bg.append(frame)\n",
        "        prev_frame = frame\n",
        "    else:\n",
        "        break\n",
        "#cap.release()\n",
        "-->"
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}